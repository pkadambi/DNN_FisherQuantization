{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "% load_ext autoreload\n",
    "% autoreload 2\n",
    "# Plot configurations\n",
    "% matplotlib inline\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from cifar_utils import load_data\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/cifar-10-python.tar.gz already exists. Begin extracting...\n"
     ]
    }
   ],
   "source": [
    "# Load the raw CIFAR-10 data.\n",
    "X_train, y_train = load_data(mode='train')\n",
    "\n",
    "mask = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(mask)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## global contrast normalization ######################\n",
    "lamda = 10\n",
    "epsilon = 1e-7\n",
    "\n",
    "#Because of memory issue, the pre-process of test data has to be after training data\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train = X_train.astype(np.float32) - mean_image.astype(np.float32)\n",
    "contrast = np.sqrt(lamda + np.mean(X_train**2,axis=0))\n",
    "X_train = X_train / np.maximum(contrast, epsilon)\n",
    "\n",
    "################## ZCA whitening #########################\n",
    "temp = []\n",
    "principal_components = []\n",
    "for c in range(3):\n",
    "    X = X_train[:,c*1024:(c+1)*1024]\n",
    "    cov = np.dot(X.T, X) / (X.shape[0]-1)\n",
    "    u, s, _ = np.linalg.svd(cov)\n",
    "    principal_components.append( np.dot(np.dot(u, np.diag(1. / np.sqrt(s + 10e-7))), u.T) )\n",
    "\n",
    "    # Apply ZCA whitening\n",
    "    whitex = np.dot(X, principal_components[c])\n",
    "    temp.append(whitex)\n",
    "\n",
    "X_train = np.append(temp[0],temp[1],axis=1)\n",
    "X_train = np.append(X_train,temp[2],axis=1)\n",
    "X_train = X_train.reshape([50000,3,32,32]).transpose((0,2,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/cifar-10-python.tar.gz already exists. Begin extracting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (45000, 32, 32, 3)\nTrain labels shape:  (45000,)\nValidation data shape:  (5000, 32, 32, 3)\nValidation labels shape:  (5000,)\n"
     ]
    }
   ],
   "source": [
    "num_training = 45000\n",
    "num_validation = 5000\n",
    "\n",
    "X_val = X_train[-num_validation:, :]\n",
    "y_val = y_train[-num_validation:]\n",
    "\n",
    "X_train = X_train[:num_training, :]\n",
    "y_train = y_train[:num_training]\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "X_test, y_test = load_data(mode='test')\n",
    "X_test = X_test.astype(np.float32) - mean_image\n",
    "contrast = np.sqrt(lamda + np.mean(X_test**2,axis=0))\n",
    "X_test = X_test / np.maximum(contrast, epsilon)\n",
    "\n",
    "for c in range(3): \n",
    "    X = X_test[:,c*1024:(c+1)*1024]\n",
    "    whitex = np.dot(X, principal_components[c])\n",
    "    temp[c] = whitex\n",
    "\n",
    "X_test = np.append(temp[0],temp[1],axis=1)\n",
    "X_test = np.append(X_test,temp[2],axis=1)\n",
    "X_test = X_test.reshape([10000,3,32,32]).transpose((0,2,3,1))\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "#print('Test data shape: ', X_test.shape)\n",
    "#print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del temp\n",
    "del whitex\n",
    "del principal_components\n",
    "del u\n",
    "del s\n",
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Incompatible return types of true_fn and false_fn: The two structures don't have the same nested structure.\n\nFirst structure: type=tuple str=([<tf.Tensor 'Adam_optimize/cond/truediv:0' shape=(3, 3, 3, 128) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_1:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_2:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_3:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_4:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_5:0' shape=(3, 3, 512, 512) dtype=float32>], [<tf.Tensor 'Adam_optimize/cond/truediv_6:0' shape=(128,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_7:0' shape=(128,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_8:0' shape=(256,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_9:0' shape=(256,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_10:0' shape=(512,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_11:0' shape=(512,) dtype=float32>], [<tf.Tensor 'Adam_optimize/cond/truediv_12:0' shape=(512, 1024) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_13:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_14:0' shape=(1024, 10) dtype=float32>], [<tf.Tensor 'Adam_optimize/cond/truediv_15:0' shape=(1024,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_16:0' shape=(1024,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_17:0' shape=(10,) dtype=float32>], <tf.Tensor 'Adam_optimize/cond/Assign:0' shape=() dtype=float32_ref>)\n\nSecond structure: type=tuple str=((0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0), <tf.Variable 'timestep:0' shape=() dtype=float32_ref>)\n\nMore specifically: The two namedtuples don't have the same sequence type. First structure type=list str=[<tf.Tensor 'Adam_optimize/cond/truediv:0' shape=(3, 3, 3, 128) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_1:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_2:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_3:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_4:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_5:0' shape=(3, 3, 512, 512) dtype=float32>] has type list, while second structure type=tuple str=(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0) has type tuple",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   2060\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m       \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_res_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_res_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36massert_same_structure\u001b[0;34m(nest1, nest2, check_types)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \"\"\"\n\u001b[0;32m--> 182\u001b[0;31m   \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAssertSameStructure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnest2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=tuple str=([<tf.Tensor 'Adam_optimize/cond/truediv:0' shape=(3, 3, 3, 128) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_1:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_2:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_3:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_4:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_5:0' shape=(3, 3, 512, 512) dtype=float32>], [<tf.Tensor 'Adam_optimize/cond/truediv_6:0' shape=(128,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_7:0' shape=(128,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_8:0' shape=(256,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_9:0' shape=(256,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_10:0' shape=(512,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_11:0' shape=(512,) dtype=float32>], [<tf.Tensor 'Adam_optimize/cond/truediv_12:0' shape=(512, 1024) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_13:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_14:0' shape=(1024, 10) dtype=float32>], [<tf.Tensor 'Adam_optimize/cond/truediv_15:0' shape=(1024,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_16:0' shape=(1024,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_17:0' shape=(10,) dtype=float32>], <tf.Tensor 'Adam_optimize/cond/Assign:0' shape=() dtype=float32_ref>)\n\nSecond structure: type=tuple str=((0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0), <tf.Variable 'timestep:0' shape=() dtype=float32_ref>)\n\nMore specifically: The two namedtuples don't have the same sequence type. First structure type=list str=[<tf.Tensor 'Adam_optimize/cond/truediv:0' shape=(3, 3, 3, 128) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_1:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_2:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_3:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_4:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_5:0' shape=(3, 3, 512, 512) dtype=float32>] has type list, while second structure type=tuple str=(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0) has type tuple",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-dd8bcc5df59c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m          \u001b[0mis_drop_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m          \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m          pre_trained_model = None)\n\u001b[0m",
      "\u001b[0;32m~/CIFAR10_binconnect/binary.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(X_train, y_train, X_val, y_val, X_test, y_test, is_binary, is_stochastic, conv_featmap, fc_units, conv_kernel_size, pooling_size, lr_start, lr_end, epoch, batch_size, is_drop_out, verbose, pre_trained_model, record_tensorboard)\u001b[0m\n\u001b[1;32m    851\u001b[0m                                      \u001b[0mconv_kernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_kernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                                      \u001b[0mpooling_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpooling_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                                      learning_rate=learning_rate)\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[0miters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CIFAR10_binconnect/binary.py\u001b[0m in \u001b[0;36mNetwork\u001b[0;34m(input_x, input_y, is_training, is_drop_out, is_binary, is_stochastic, channel_num, output_size, conv_featmap, fc_units, conv_kernel_size, pooling_size, learning_rate)\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0mfc_layer_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfc_layer_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc_layer_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc_layer_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m     \u001b[0m_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madam_optimizer_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_layer_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_layer_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc_layer_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfc_layer_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;31m# with tf.name_scope(\"Adam_optimize\"):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CIFAR10_binconnect/binary.py\u001b[0m in \u001b[0;36madam_optimizer_bn\u001b[0;34m(loss, learning_rate, is_training, is_binary, conv_layer_list, fc_layer_list)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0;31m# if is_training, do update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0mconv_updates_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_updates_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc_updates_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc_updates_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0;31m# adjust learning rate with beta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                 instructions)\n\u001b[0;32m--> 432\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    434\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   2062\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m       raise TypeError(\n\u001b[0;32m-> 2064\u001b[0;31m           \"Incompatible return types of true_fn and false_fn: {}\".format(e))\n\u001b[0m\u001b[1;32m   2065\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m       raise ValueError(\n",
      "\u001b[0;31mTypeError\u001b[0m: Incompatible return types of true_fn and false_fn: The two structures don't have the same nested structure.\n\nFirst structure: type=tuple str=([<tf.Tensor 'Adam_optimize/cond/truediv:0' shape=(3, 3, 3, 128) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_1:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_2:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_3:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_4:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_5:0' shape=(3, 3, 512, 512) dtype=float32>], [<tf.Tensor 'Adam_optimize/cond/truediv_6:0' shape=(128,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_7:0' shape=(128,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_8:0' shape=(256,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_9:0' shape=(256,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_10:0' shape=(512,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_11:0' shape=(512,) dtype=float32>], [<tf.Tensor 'Adam_optimize/cond/truediv_12:0' shape=(512, 1024) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_13:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_14:0' shape=(1024, 10) dtype=float32>], [<tf.Tensor 'Adam_optimize/cond/truediv_15:0' shape=(1024,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_16:0' shape=(1024,) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_17:0' shape=(10,) dtype=float32>], <tf.Tensor 'Adam_optimize/cond/Assign:0' shape=() dtype=float32_ref>)\n\nSecond structure: type=tuple str=((0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0), <tf.Variable 'timestep:0' shape=() dtype=float32_ref>)\n\nMore specifically: The two namedtuples don't have the same sequence type. First structure type=list str=[<tf.Tensor 'Adam_optimize/cond/truediv:0' shape=(3, 3, 3, 128) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_1:0' shape=(3, 3, 128, 128) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_2:0' shape=(3, 3, 128, 256) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_3:0' shape=(3, 3, 256, 256) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_4:0' shape=(3, 3, 256, 512) dtype=float32>, <tf.Tensor 'Adam_optimize/cond/truediv_5:0' shape=(3, 3, 512, 512) dtype=float32>] has type list, while second structure type=tuple str=(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0) has type tuple"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# No Regularizer\n",
    "from binary import training\n",
    "tf.reset_default_graph()\n",
    "training(X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "                     is_binary = False, \n",
    "                     is_stochastic = False, \n",
    "                     conv_featmap = [128, 128, 256, 256, 512, 512],\n",
    "                     fc_units = [1024, 1024],\n",
    "                     conv_kernel_size = [3, 3, 3, 3, 3, 3],\n",
    "         pooling_size = [2, 2, 2],\n",
    "         lr_start = 0.001,\n",
    "         lr_end = 0.0001, \n",
    "         epoch = 20,\n",
    "         batch_size = 50,\n",
    "         is_drop_out = False,\n",
    "         verbose = True,\n",
    "         pre_trained_model = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches for training: 900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss: 0.6243072298169136 ,  average accuracy : 49.14%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy : 51.12%\n* Best accuracy: 51.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss: 0.49118662231498295 ,  average accuracy : 70.74222222222222%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy : 65.24000000000001%\n* Best accuracy: 65.24000000000001%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss: 0.46537928813033635 ,  average accuracy : 76.55555555555556%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy : 69.06%\n* Best accuracy: 69.06%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss: 0.44859808643658955 ,  average accuracy : 80.44444444444444%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy : 75.53999999999999%\n* Best accuracy: 75.53999999999999%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss: 0.4347781567772229 ,  average accuracy : 83.68444444444444%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy : 74.7%\nepoch 6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss: 0.4238867561022441 ,  average accuracy : 86.48444444444445%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy : 77.4%\n* Best accuracy: 77.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss: 0.41501058194372387 ,  average accuracy : 88.58444444444444%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy : 79.24%\n* Best accuracy: 79.24%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss: 0.4063669154047966 ,  average accuracy : 90.98666666666666%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy : 77.48%\nepoch 9 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss: 0.4011721666322814 ,  average accuracy : 92.28888888888889%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy : 76.66%\nepoch 10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss: 0.39635968191756143 ,  average accuracy : 93.41111111111111%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy : 80.3%\n* Best accuracy: 80.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss: 0.39295094079441495 ,  average accuracy : 94.27555555555556%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy : 78.82%\nepoch 12 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss: 0.39114324506786136 ,  average accuracy : 94.79777777777778%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy : 81.18%\n* Best accuracy: 81.18%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss: 0.3874173891875479 ,  average accuracy : 95.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy : 80.56%\nepoch 14 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss: 0.3870201612181134 ,  average accuracy : 95.83555555555556%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy : 81.14%\nepoch 15 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss: 0.3857903302046988 ,  average accuracy : 96.18666666666667%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy : 80.9%\nepoch 16 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss: 0.3849865636560652 ,  average accuracy : 96.3711111111111%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy : 80.12%\nepoch 17 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-096910dc1a97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m          \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m          \u001b[0mpre_trained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m          record_tensorboard=False)\n\u001b[0m",
      "\u001b[0;32m~/CIFAR10_binconnect/binary.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(X_train, y_train, X_val, y_val, X_test, y_test, is_binary, is_stochastic, conv_featmap, fc_units, conv_kernel_size, pooling_size, lr_start, lr_end, epoch, batch_size, is_drop_out, verbose, pre_trained_model, record_tensorboard)\u001b[0m\n\u001b[1;32m    770\u001b[0m                         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msumm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m                         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_eve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meve\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_batch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_batch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m                     \u001b[0mtotal_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# BinaryConnect det.\n",
    "from binary import training\n",
    "tf.reset_default_graph()\n",
    "training(X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "         is_binary = True, \n",
    "         is_stochastic = False, \n",
    "         conv_featmap = [128, 128, 256, 256, 512, 512],\n",
    "         fc_units = [1024, 1024],\n",
    "         conv_kernel_size = [3, 3, 3, 3, 3, 3],\n",
    "         pooling_size = [2, 2, 2],\n",
    "         lr_start = 0.01,\n",
    "         lr_end = 0.001, \n",
    "         epoch = 200,\n",
    "         batch_size = 50,\n",
    "         is_drop_out = False,\n",
    "         verbose = True,\n",
    "         pre_trained_model = None,\n",
    "         record_tensorboard=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_val' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-38cf5e8612a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m training(X_train, y_train, X_val, y_val, X_test, y_test,\n\u001b[0m\u001b[1;32m      5\u001b[0m          \u001b[0mis_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m          \u001b[0mis_stochastic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_val' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# BinaryConnect stoch.\n",
    "from binary import training\n",
    "tf.reset_default_graph()\n",
    "training(X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "         is_binary = True, \n",
    "         is_stochastic = True, \n",
    "         conv_featmap = [128, 128, 256, 256, 512, 512],\n",
    "         fc_units = [1024, 1024],\n",
    "         conv_kernel_size = [3, 3, 3, 3, 3, 3],\n",
    "         pooling_size = [2, 2, 2],\n",
    "         lr_start = 0.1,\n",
    "         lr_end = 0.0001, \n",
    "         epoch = 50,\n",
    "         batch_size = 50,\n",
    "         is_drop_out = False,\n",
    "         verbose = True,\n",
    "         pre_trained_model = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}